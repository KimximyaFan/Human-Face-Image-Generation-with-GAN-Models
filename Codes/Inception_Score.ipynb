{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"L4","machine_shape":"hm","authorship_tag":"ABX9TyOfCPEwedp0DldaUrNqJ1hB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"jMt1j8oM-9Ee"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch torchvision torchmetrics\n","!pip install torch-fidelity"],"metadata":{"id":"7GbH1dBJCKPG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# 압축 파일은 celeba 폴더에\n","# =========================\n","\n","img_zip_file = 'dcgan_front_50_epoch.zip'"],"metadata":{"id":"HxwZSL5NIVzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==========\n","# 압축 해제\n","# ==========\n","\n","import os\n","import shutil\n","\n","source_path = f'/content/drive/MyDrive/celeba/{img_zip_file}'\n","copy_path = '/content/example.zip'\n","extract_path = '/content/extracted'\n","\n","folder_name = os.path.splitext(img_zip_file)[0]\n","\n","shutil.copy(source_path, copy_path)\n","\n","if not os.path.exists(extract_path):\n","    os.makedirs(extract_path)\n","\n","!unzip -q {copy_path} -d {extract_path}\n","\n","inner_dir = os.path.join(extract_path, folder_name)\n","\n","if os.path.isdir(inner_dir):\n","    for filename in os.listdir(inner_dir):\n","        src_path = os.path.join(inner_dir, filename)\n","        dst_path = os.path.join(extract_path, filename)\n","        shutil.move(src_path, dst_path)\n","    os.rmdir(inner_dir)"],"metadata":{"id":"y4lqswnw--M5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s714K2pt8DcU"},"outputs":[],"source":["# ================\n","# Inception Score\n","# ================\n","\n","import torch\n","from torchmetrics.image.inception import InceptionScore\n","from torchvision.transforms import ToTensor, Resize\n","from PIL import Image\n","import os\n","\n","# IS 객체 초기화\n","inception = InceptionScore(normalize=True)\n","\n","generated_images_path = \"/content/extracted\"  # 본인 환경에 맞게 설정\n","image_files = [f for f in os.listdir(generated_images_path) if f.endswith(\".png\") or f.endswith(\".jpg\")]\n","\n","# 배치 크기 설정\n","batch_size = 100\n","\n","# 이미지 전처리를 위한 transform\n","resize_transform = Resize((299, 299))\n","\n","for i in range(0, len(image_files), batch_size):\n","    batch_files = image_files[i:i + batch_size]\n","    batch_tensors = []\n","\n","    for filename in batch_files:\n","        img_path = os.path.join(generated_images_path, filename)\n","        img = Image.open(img_path).convert(\"RGB\")\n","        img = resize_transform(img)\n","        img_tensor = ToTensor()(img).unsqueeze(0)\n","        batch_tensors.append(img_tensor)\n","\n","    # 현재 batch 이미지들을 하나의 텐서로 합친 후 InceptionScore에 업데이트\n","    batch_tensors = torch.cat(batch_tensors, dim=0)  # shape: [batch_size, 3, 299, 299]\n","    inception.update(batch_tensors)\n","\n","# 모든 배치 업데이트가 끝난 후 최종적으로 점수 계산\n","score, std = inception.compute()\n","\n","print(\"\\n\")\n","print(img_zip_file)\n","print(f\"Inception Score: {score:.4f} ± {std:.4f}\")"]}]}