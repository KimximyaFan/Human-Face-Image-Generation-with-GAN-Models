{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"L4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kUasjdBPEz6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","print(os.cpu_count())\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""],"metadata":{"id":"hI6vusB-esy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-P828eOyUi_"},"outputs":[],"source":["#%matplotlib inline\n","import argparse\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","\n","# 코드 실행결과의 동일성을 위해 무작위 시드를 설정합니다\n","manualSeed = 999\n","#manualSeed = random.randint(1, 10000) # 만일 새로운 결과를 원한다면 주석을 없애면 됩니다\n","print(\"Random Seed: \", manualSeed)\n","random.seed(manualSeed)\n","torch.manual_seed(manualSeed)\n","torch.use_deterministic_algorithms(True) # 결과 재현을 위해 필요합니다"]},{"cell_type":"code","source":["import shutil\n","\n","# Google Drive에서 로컬로 파일 복사\n","shutil.copy('/content/drive/MyDrive/celeba/front_faces.zip', '/content/example.zip')\n","\n","# 로컬에서 압축 해제\n","!unzip -q /content/example.zip -d /content/extracted"],"metadata":{"id":"n7yqLafo5aL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# 디렉토리 경로\n","extract_path = '/content/extracted'\n","\n","total_files = 0\n","total_size = 0\n","\n","for root, dirs, files in os.walk(extract_path):\n","    for file in files:\n","        file_path = os.path.join(root, file)\n","        file_size = os.path.getsize(file_path)\n","        total_files += 1\n","        total_size += file_size\n","\n","print(f\"총 파일 개수: {total_files}\")\n","print(f\"총 파일 크기: {total_size / (1024 * 1024):.2f} MB\")"],"metadata":{"id":"2RaCjeGc5fPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋의 경로\n","dataroot = \"/content/extracted\" #\"/content/drive/MyDrive/celeba\"\n","\n","# dataloader에서 사용할 쓰레드 수\n","workers = os.cpu_count()\n","\n","# 배치 크기\n","batch_size = 128 #os.cpu_count() #64 #128 #1024\n","\n","# 이미지의 크기입니다. 모든 이미지를 변환하여 64로 크기가 통일됩니다.\n","image_size = 64\n","\n","# 이미지의 채널 수로, RGB 이미지이기 때문에 3으로 설정합니다.\n","nc = 3\n","\n","# 잠재공간 벡터의 크기 (예. 생성자의 입력값 크기)\n","nz = 100\n","\n","# 생성자를 통과하는 특징 데이터들의 채널 크기\n","ngf = 64\n","\n","# 구분자를 통과하는 특징 데이터들의 채널 크기\n","ndf = 64\n","\n","# 학습할 에폭 수\n","num_epochs = 5\n","\n","# 옵티마이저의 학습률\n","lr = 0.0002\n","\n","# Adam 옵티마이저의 beta1 하이퍼파라미터\n","beta1 = 0.5\n","\n","# 사용가능한 gpu 번호. CPU를 사용해야 하는경우 0으로 설정하세요\n","ngpu = 1"],"metadata":{"id":"MMiBeLUbymKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms, datasets\n","data_len = (len(datasets.ImageFolder(root=dataroot, transform=None)))\n","print(data_len)"],"metadata":{"id":"eHJPt10fjBIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 우리가 설정한 대로 이미지 데이터셋을 불러와 봅시다\n","# 먼저 데이터셋을 만듭니다\n","dataset = dset.ImageFolder(root=dataroot,\n","                           transform=transforms.Compose([\n","                               transforms.Resize(image_size),\n","                               transforms.CenterCrop(image_size),\n","                               transforms.ToTensor(),\n","                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                           ]))\n","# dataloader를 정의해봅시다\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                         shuffle=True, num_workers=workers)\n","\n","# GPU 사용여부를 결정해 줍니다\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","\n","# 학습 데이터들 중 몇가지 이미지들을 화면에 띄워봅시다\n","real_batch = next(iter(dataloader))\n","plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","plt.title(\"Training Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n","plt.show()"],"metadata":{"id":"APltaYxTFO-B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(dataloader))"],"metadata":{"id":"Rfi9e4_oK1AS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ``netG`` 와 ``netD`` 에 적용시킬 커스텀 가중치 초기화 함수\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"],"metadata":{"id":"7M_IXVP1FRlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 생성자 코드\n","\n","class Generator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Generator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            # 입력데이터 Z가 가장 처음 통과하는 전치 합성곱 계층입니다.\n","            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ngf*8) x 4 x 4``\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ngf*4) x 8 x 8``\n","            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ngf*2) x 16 x 16``\n","            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ngf) x 32 x 32``\n","            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # 위의 계층을 통과한 데이터의 크기. ``(nc) x 64 x 64``\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"],"metadata":{"id":"LHgXf4a4HSSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 생성자를 만듭니다\n","netG = Generator(ngpu).to(device)\n","\n","# 필요한 경우 multi-GPU를 설정 해주세요\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netG = nn.DataParallel(netG, list(range(ngpu)))\n","\n","# 모든 가중치의 평균을 0( ``mean=0`` ), 분산을 0.02( ``stdev=0.02`` )로 초기화하기 위해\n","# ``weight_init`` 함수를 적용시킵니다\n","netG.apply(weights_init)\n","\n","# 모델의 구조를 출력합니다\n","print(netG)"],"metadata":{"id":"ki6nzwwXHUF7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 구분자 코드\n","\n","class Critic(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Critic, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            # 입력 데이터의 크기는 ``(nc) x 64 x 64`` 입니다\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ndf) x 32 x 32``\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ndf*2) x 16 x 16``\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ndf*4) x 8 x 8``\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 위의 계층을 통과한 데이터의 크기. ``(ndf*8) x 4 x 4``\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"],"metadata":{"id":"hZxHVzRjHYyE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 구분자를 만듭니다\n","netD = Critic(ngpu).to(device)\n","\n","# 필요한 경우 multi-GPU를 설정 해주세요\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netD = nn.DataParallel(netD, list(range(ngpu)))\n","\n","# 모든 가중치의 평균을 0( ``mean=0`` ), 분산을 0.02( ``stdev=0.02`` )로 초기화하기 위해\n","# ``weight_init`` 함수를 적용시킵니다\n","netD.apply(weights_init)\n","\n","# 모델의 구조를 출력합니다\n","print(netD)"],"metadata":{"id":"x7aMOK14IXv9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 그래디언트 패널티 계산 함수\n","def gradient_penalty(critic, real_data, fake_data, device, lambda_gp=10):\n","    batch_size, c, h, w = real_data.size()\n","    epsilon = torch.rand(batch_size, 1, 1, 1, device=device).expand_as(real_data)\n","    interpolated = epsilon * real_data + (1 - epsilon) * fake_data\n","    interpolated.requires_grad_(True)\n","    critic_output = critic(interpolated)\n","    gradients = torch.autograd.grad(\n","        outputs=critic_output,\n","        inputs=interpolated,\n","        grad_outputs=torch.ones_like(critic_output, device=device),\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True\n","    )[0]\n","    gradients = gradients.view(batch_size, -1)\n","    gradient_norm = gradients.norm(2, dim=1)\n","    penalty = lambda_gp * ((gradient_norm - 1) ** 2).mean()\n","    return penalty\n","\n","# 손실 함수 정의\n","def generator_loss(fake_scores):\n","    return -fake_scores.mean()\n","\n","def critic_loss(real_scores, fake_scores):\n","    return fake_scores.mean() - real_scores.mean()"],"metadata":{"id":"mizx586hU9eZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 생성자의 학습상태를 확인할 잠재 공간 벡터를 생성합니다\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# G와 D에서 사용할 Adam옵티마이저를 생성합니다\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"metadata":{"id":"j7v5CnFBIZVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 과정\n","\n","# 학습상태를 체크하기 위해 손실값들을 저장합니다\n","n_critic = 5  # Critic 업데이트 횟수\n","lambda_gp = 10  # Gradient Penalty 계수\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","\n","print(\"Starting Training Loop...\")\n","# 에폭(epoch) 반복\n","for epoch in range(num_epochs):\n","    # 한 에폭 내에서 배치 반복\n","    for i, data in enumerate(dataloader, 0):\n","\n","        ############################\n","        # (1) D 신경망을 업데이트 합니다: log(D(x)) + log(1 - D(G(z)))를 최대화 합니다\n","        ###########################\n","        ## 진짜 데이터들로 학습을 합니다\n","        netD.zero_grad()\n","        # 배치들의 사이즈나 사용할 디바이스에 맞게 조정합니다\n","        real_data  = data[0].to(device)\n","        batch_size = real_data.size(0)\n","\n","        # 진짜 데이터\n","        real_scores = netD(real_data).view(-1)\n","\n","        # 가짜 데이터\n","        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n","        fake_data = netG(noise).detach()  # 그래프 분리\n","        fake_scores = netD(fake_data).view(-1)\n","\n","        # 그래디언트 패널티 계산\n","        gp = gradient_penalty(netD, real_data, fake_data, device, lambda_gp)\n","\n","        # Critic 손실 계산 및 업데이트\n","        loss_critic = critic_loss(real_scores, fake_scores) + gp\n","        loss_critic.backward()\n","        optimizerD.step()\n","\n","        # Critic 업데이트 후 Generator 업데이트\n","        if i % n_critic == 0:\n","            ############################\n","            # (2) Generator 업데이트\n","            ###########################\n","            netG.zero_grad()\n","            fake_data = netG(noise)  # 새로 생성\n","            fake_scores = netD(fake_data).view(-1)\n","            loss_generator = generator_loss(fake_scores)\n","            loss_generator.backward()\n","            optimizerG.step()\n","\n","        # 훈련 상태를 출력합니다\n","        if i % 50 == 0:\n","            print(f\"[{epoch}/{num_epochs}][{i}/{len(dataloader)}]\\t\"\n","                  f\"Loss_Critic: {loss_critic.item():.4f}\\tLoss_G: {loss_generator.item():.4f}\")\n","\n","\n","        # 이후 그래프를 그리기 위해 손실값들을 저장해둡니다\n","        G_losses.append(loss_generator.item())\n","        D_losses.append(loss_critic.item())\n","\n","        # fixed_noise를 통과시킨 G의 출력값을 저장해둡니다\n","        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n","            with torch.no_grad():\n","                fake = netG(fixed_noise).detach().cpu()\n","            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1"],"metadata":{"id":"skNsmnFTIj5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(G_losses,label=\"G\")\n","plt.plot(D_losses,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"PrUmTP_zIybb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n","ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n","\n","HTML(ani.to_jshtml())"],"metadata":{"id":"JtnKBcZvI0Ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataloader에서 진짜 데이터들을 가져옵니다\n","real_batch = next(iter(dataloader))\n","\n","# 진짜 이미지들을 화면에 출력합니다\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n","\n","# 가짜 이미지들을 화면에 출력합니다\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Fake Images\")\n","plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n","plt.show()"],"metadata":{"id":"hO6mJoNwI2-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cUpWGVIGFSqa"},"execution_count":null,"outputs":[]}]}